From 24bd0ac2c443438695de82e446833e9b0a060b6f Mon Sep 17 00:00:00 2001
From: Angie Chinchilla <angie.v.chinchilla@intel.com>
Date: Mon, 5 Jun 2017 11:08:18 -0400
Subject: [PATCH] SGX 2.0 Implementation

Authors:
Serge Ayoun <serge.ayoun@intel.com>
Angie Chinchilla <angie.v.chinchilla@intel.com>
Shay Katz-zamir <shay.katz-zamir@intel.com>
Cedric Xing <cedric.xing@intel.com>

Signed-off-by: Angie Chinchilla <angie.v.chinchilla@intel.com>
---
 Makefile         |   2 +-
 README.md        |   3 +-
 sgx.h            |  28 ++-
 sgx_arch.h       |   5 +-
 sgx_ioctl.c      | 545 +++++++++++++++++++++++++++++++++++++++++++++++++++++--
 sgx_main.c       |   2 +-
 sgx_page_cache.c |  21 ++-
 sgx_user.h       |  29 +++
 sgx_util.c       |  28 ++-
 sgx_vma.c        |  11 +-
 10 files changed, 642 insertions(+), 32 deletions(-)

diff --git a/Makefile b/Makefile
index 896d397..11f2927 100644
--- a/Makefile
+++ b/Makefile
@@ -20,4 +20,4 @@ install: default
 endif
 
 clean:
-	rm -vrf *.o *.ko *.order *.symvers *.mod.c .tmp_versions .*o.cmd
+	rm -vrf *.o *.ko *.order *.symvers *.mod.c .tmp_versions .*o.cmd .*.o.d
diff --git a/README.md b/README.md
index a8b2b04..61946c4 100644
--- a/README.md
+++ b/README.md
@@ -19,6 +19,7 @@ Contributing
 -------
 Starting from 05/2017, we are importing the sgx driver code from the in-kernel sgx repository located at git-hub: https://github.com/jsakkine-intel/linux-sgx.git. Any contribution should be done there. Future versions of the sgx driver code will be imported later on. The motivation behind this decision is to maintain a single source code of the sgx linux driver.
 An additional directory inker2ext/ has been created, it contains a script and a patch file that can be used in order to separately generate the code base of the sgx external module; it can be used in case someone wants the newest sgx driver as an external module and does not want to wait for next update.
+The sgx2 branch hosts an initial implementation supporting SGX 2.0. This patch is maintained in inker2ext/sgx2.patch in the 2.0 branch and will be periodically updated to the linux-sgx-driver:master branch. Contributions for this patch should be managed directly through the linux-sgx-driver project on Github. sgx2 will have the same behavior as linux-sgx-driver on hardware platforms that do not support SGX 2.0.
 
 Documentation
 -------------
@@ -31,7 +32,7 @@ Build and Install the Intel(R) SGX Driver
 ### Prerequisites
 - Ensure that you have the following required operating systems:  
   * Ubuntu* Desktop-16.04-LTS 64bits
-  * Red Hat Enterprise Linux Server release 7.2 64bits
+  * Red Hat Enterprise Linux Server release 7.3 64bits
   * CentOS 7.3.1611 64bits
 - Ensure that you have the following required hardware:  
   * 6th Generation Intel(R) Core(TM) Processor (code named Skylake)
diff --git a/sgx.h b/sgx.h
index 01dcfb3..0dae86c 100644
--- a/sgx.h
+++ b/sgx.h
@@ -69,11 +69,13 @@
 #include <linux/workqueue.h>
 #include <linux/mmu_notifier.h>
 #include <linux/radix-tree.h>
+#include <linux/mm.h>
 #include "sgx_arch.h"
 
 #define SGX_EINIT_SPIN_COUNT	20
 #define SGX_EINIT_SLEEP_COUNT	50
 #define SGX_EINIT_SLEEP_TIME	20
+#define SGX_EDMM_SPIN_COUNT	20
 
 #define SGX_VA_SLOT_COUNT 512
 
@@ -99,9 +101,21 @@ static inline void sgx_free_va_slot(struct sgx_va_page *page,
 	clear_bit(offset >> 3, page->slots);
 }
 
+static inline bool sgx_va_slots_empty(struct sgx_va_page *page)
+{
+	int slot = find_first_bit(page->slots, SGX_VA_SLOT_COUNT);
+
+	if (slot == SGX_VA_SLOT_COUNT)
+		return true;
+
+	return false;
+}
+
 enum sgx_encl_page_flags {
 	SGX_ENCL_PAGE_TCS	= BIT(0),
 	SGX_ENCL_PAGE_RESERVED	= BIT(1),
+	SGX_ENCL_PAGE_TRIM	= BIT(2),
+	SGX_ENCL_PAGE_ADDED	= BIT(3),
 };
 
 struct sgx_encl_page {
@@ -147,6 +161,7 @@ struct sgx_encl {
 	struct sgx_tgid_ctx *tgid_ctx;
 	struct list_head encl_list;
 	struct mmu_notifier mmu_notifier;
+	unsigned int shadow_epoch;
 };
 
 struct sgx_epc_bank {
@@ -210,11 +225,22 @@ enum sgx_fault_flags {
 
 struct sgx_encl_page *sgx_fault_page(struct vm_area_struct *vma,
 				     unsigned long addr,
-				     unsigned int flags);
+				     unsigned int flags,
+				     struct vm_fault *vmf);
 
 void sgx_encl_release(struct kref *ref);
 void sgx_tgid_ctx_release(struct kref *ref);
 
+void sgx_ipi_cb(void *info);
+bool sgx_etrack(struct sgx_encl *encl, unsigned int epoch);
+struct sgx_encl_page *sgx_augment_encl(struct vm_area_struct *vma,
+				       unsigned long addr,
+				       bool write);
+int sgx_eldu(struct sgx_encl *encl,
+	     struct sgx_encl_page *encl_page,
+	     struct sgx_epc_page *epc_page,
+	     bool is_secs);
+
 extern struct mutex sgx_tgid_ctx_mutex;
 extern struct list_head sgx_tgid_ctx_list;
 extern struct task_struct *ksgxswapd_tsk;
diff --git a/sgx_arch.h b/sgx_arch.h
index 233d3a6..6d2fea9 100644
--- a/sgx_arch.h
+++ b/sgx_arch.h
@@ -81,6 +81,7 @@ enum sgx_secinfo_flags {
 	SGX_SECINFO_SECS	= 0x000ULL,
 	SGX_SECINFO_TCS		= 0x100ULL,
 	SGX_SECINFO_REG		= 0x200ULL,
+	SGX_SECINFO_TRIM	= 0x400ULL,
 };
 
 struct sgx_secinfo {
@@ -105,7 +106,7 @@ enum isgx_secs_attributes {
 					   GENMASK_ULL(63, 6)),
 };
 
-#define SGX_SECS_RESERVED1_SIZE 28
+#define SGX_SECS_RESERVED1_SIZE 24
 #define SGX_SECS_RESERVED2_SIZE 32
 #define SGX_SECS_RESERVED3_SIZE 96
 #define SGX_SECS_RESERVED4_SIZE 3836
@@ -114,6 +115,7 @@ struct sgx_secs {
 	u64	size;
 	u64	base;
 	u32	ssaframesize;
+	u32	misc_select;
 	uint8_t reserved1[SGX_SECS_RESERVED1_SIZE];
 	u64	flags;
 	u64	xfrm;
@@ -339,6 +341,7 @@ static inline int __emodt(struct sgx_secinfo *secinfo, void *epc)
 	return __encls_ret(EMODT, secinfo, epc, rdx);
 }
 
+
 struct sgx_encl;
 
 struct sgx_epc_page {
diff --git a/sgx_ioctl.c b/sgx_ioctl.c
index f2519a5..9cedfd3 100644
--- a/sgx_ioctl.c
+++ b/sgx_ioctl.c
@@ -73,6 +73,8 @@
 #include <linux/hashtable.h>
 #include <linux/shmem_fs.h>
 
+#define SGX_NR_MOD_CHUNK_PAGES 16
+
 struct sgx_add_page_req {
 	struct sgx_encl *encl;
 	struct sgx_encl_page *encl_page;
@@ -274,6 +276,7 @@ static bool sgx_process_add_page_req(struct sgx_add_page_req *req)
 	encl_page->epc_page = epc_page;
 	sgx_test_and_clear_young(encl_page, encl);
 	list_add_tail(&encl_page->load_list, &encl->load_list);
+	encl_page->flags |= SGX_ENCL_PAGE_ADDED;
 
 	mutex_unlock(&encl->lock);
 	up_read(&encl->mm->mmap_sem);
@@ -390,7 +393,9 @@ static int sgx_validate_secs(const struct sgx_secs *secs)
 
 static int sgx_init_page(struct sgx_encl *encl,
 			 struct sgx_encl_page *entry,
-			 unsigned long addr)
+			 unsigned long addr,
+			 struct sgx_epc_page **va_src,
+			 bool already_locked)
 {
 	struct sgx_va_page *va_page;
 	struct sgx_epc_page *epc_page = NULL;
@@ -409,10 +414,15 @@ static int sgx_init_page(struct sgx_encl *encl,
 		if (!va_page)
 			return -ENOMEM;
 
-		epc_page = sgx_alloc_page(0);
-		if (IS_ERR(epc_page)) {
-			kfree(va_page);
-			return PTR_ERR(epc_page);
+		if (va_src) {
+			epc_page = *va_src;
+			*va_src = NULL;
+		} else {
+			epc_page = sgx_alloc_page(0);
+			if (IS_ERR(epc_page)) {
+				kfree(va_page);
+				return PTR_ERR(epc_page);
+			}
 		}
 
 		vaddr = sgx_get_page(epc_page);
@@ -437,9 +447,11 @@ static int sgx_init_page(struct sgx_encl *encl,
 		va_page->epc_page = epc_page;
 		va_offset = sgx_alloc_va_slot(va_page);
 
-		mutex_lock(&encl->lock);
+		if (!already_locked)
+			mutex_lock(&encl->lock);
 		list_add(&va_page->list, &encl->va_pages);
-		mutex_unlock(&encl->lock);
+		if (!already_locked)
+			mutex_unlock(&encl->lock);
 	}
 
 	entry->va_page = va_page;
@@ -556,7 +568,7 @@ static long sgx_ioc_enclave_create(struct file *filep, unsigned int cmd,
 		goto out;
 
 	ret = sgx_init_page(encl, &encl->secs_page,
-			    encl->base + encl->size);
+			    encl->base + encl->size, NULL, false);
 	if (ret)
 		goto out;
 
@@ -592,17 +604,17 @@ static long sgx_ioc_enclave_create(struct file *filep, unsigned int cmd,
 		goto out;
 	}
 
-	down_read(&current->mm->mmap_sem);
+	down_write(&current->mm->mmap_sem);
 	vma = find_vma(current->mm, secs->base);
 	if (!vma || vma->vm_ops != &sgx_vm_ops ||
 	    vma->vm_start != secs->base ||
 	    vma->vm_end != (secs->base + secs->size)) {
 		ret = -EINVAL;
-		up_read(&current->mm->mmap_sem);
+		up_write(&current->mm->mmap_sem);
 		goto out;
 	}
 	vma->vm_private_data = encl;
-	up_read(&current->mm->mmap_sem);
+	up_write(&current->mm->mmap_sem);
 
 	mutex_lock(&sgx_tgid_ctx_mutex);
 	list_add_tail(&encl->encl_list, &encl->tgid_ctx->encl_list);
@@ -697,7 +709,7 @@ static int __encl_add_page(struct sgx_encl *encl,
 		}
 	}
 
-	ret = sgx_init_page(encl, encl_page, addp->addr);
+	ret = sgx_init_page(encl, encl_page, addp->addr, NULL, false);
 	if (ret) {
 		__free_page(tmp_page);
 		return -EINVAL;
@@ -930,6 +942,500 @@ out_free_page:
 	return ret;
 }
 
+/**
+ * sgx_augment_encl() - adds a page to an enclave
+ * @addr:	virtual address where the page should be added
+ *
+ * the address is checked against the dynamic ranges defined for
+ * the enclave. If it matches one, a page is added at the
+ * corresponding location
+ *
+ * Note: Invoking function must already hold the encl->lock
+ */
+struct sgx_encl_page *sgx_augment_encl(struct vm_area_struct *vma,
+				       unsigned long addr,
+				       bool write)
+{
+	struct sgx_page_info pginfo;
+	struct sgx_epc_page *epc_page, *va_page = NULL;
+	struct sgx_epc_page *secs_epc_page = NULL;
+	struct sgx_encl_page *encl_page;
+	struct sgx_encl *encl = (struct sgx_encl *) vma->vm_private_data;
+	void *epc_va;
+	void *secs_va;
+	int ret = -EFAULT;
+
+	if (!sgx_has_sgx2)
+		return ERR_PTR(-EFAULT);
+
+	/* if vma area is not writable then we will not eaug */
+	if (unlikely(!(vma->vm_flags & VM_WRITE)))
+		return ERR_PTR(-EFAULT);
+
+	addr &= ~(PAGE_SIZE-1);
+
+	/* Note: Invoking function holds the encl->lock */
+
+	epc_page = sgx_alloc_page(SGX_ALLOC_ATOMIC);
+	if (IS_ERR(epc_page)) {
+		return ERR_PTR(PTR_ERR(epc_page));
+	}
+
+	va_page = sgx_alloc_page(SGX_ALLOC_ATOMIC);
+	if (IS_ERR(va_page)) {
+		sgx_free_page(epc_page, encl);
+		return ERR_PTR(PTR_ERR(va_page));
+	}
+
+	encl_page = kzalloc(sizeof(struct sgx_encl_page), GFP_KERNEL);
+	if (!encl_page) {
+		sgx_free_page(epc_page, encl);
+		sgx_free_page(va_page, encl);
+		return ERR_PTR(-EFAULT);
+	}
+
+	if (!(encl->flags & SGX_ENCL_INITIALIZED))
+		goto out;
+
+	if (encl->flags & SGX_ENCL_DEAD)
+		goto out;
+
+	/*
+	if ((rg->rg_desc.flags & SGX_GROW_DOWN_FLAG) && !write)
+		goto out;
+	*/
+
+	/* Start the augmenting process */
+	ret = sgx_init_page(encl, encl_page, addr, &va_page, true);
+	if (ret)
+		goto out;
+
+	/* If SECS is evicted then reload it first */
+	/* Same steps as in sgx_do_fault */
+	if (encl->flags & SGX_ENCL_SECS_EVICTED) {
+		secs_epc_page = sgx_alloc_page(SGX_ALLOC_ATOMIC);
+		if (IS_ERR(secs_epc_page)) {
+			ret = PTR_ERR(secs_epc_page);
+			secs_epc_page = NULL;
+			goto out;
+		}
+
+		ret = sgx_eldu(encl, &encl->secs_page, secs_epc_page, true);
+		if (ret)
+			goto out;
+
+		encl->secs_page.epc_page = secs_epc_page;
+		encl->flags &= ~SGX_ENCL_SECS_EVICTED;
+
+		/* Do not free */
+		secs_epc_page = NULL;
+	}
+
+	secs_va = sgx_get_page(encl->secs_page.epc_page);
+	epc_va = sgx_get_page(epc_page);
+
+	pginfo.srcpge = 0;
+	pginfo.secinfo = 0;
+	pginfo.linaddr = addr;
+	pginfo.secs = (unsigned long) secs_va;
+
+	ret = __eaug(&pginfo, epc_va);
+	if (ret) {
+		pr_err("sgx: eaug failure with ret=%d\n", ret);
+		goto out;
+	}
+
+	ret = vm_insert_pfn(vma, encl_page->addr, PFN_DOWN(epc_page->pa));
+	sgx_put_page(epc_va);
+	sgx_put_page(secs_va);
+	if (ret) {
+		pr_err("sgx: vm_insert_pfn failure with ret=%d\n", ret);
+		goto out;
+	}
+
+	encl_page->epc_page = epc_page;
+	encl->secs_child_cnt++;
+
+	ret = radix_tree_insert(&encl->page_tree, encl_page->addr >> PAGE_SHIFT,
+			        encl_page);
+	if (ret) {
+		pr_err("sgx: radix_tree_insert failed with ret=%d\n", ret);
+		goto out;
+	}
+	sgx_test_and_clear_young(encl_page, encl);
+
+	list_add_tail(&encl_page->load_list, &encl->load_list);
+	encl_page->flags |= SGX_ENCL_PAGE_ADDED;
+
+	if (va_page)
+		sgx_free_page(va_page, encl);
+	if (secs_epc_page)
+		sgx_free_page(secs_epc_page, encl);
+
+	/*
+	 * Write operation corresponds to stack extension
+	 * In this case the #PF is caused by a write operation,
+	 * most probably a push.
+	 * We return SIGBUS such that the OS invokes the enclave's exception
+	 * handler which will execute eaccept.
+	 */
+	if (write)
+		return ERR_PTR(-EFAULT);
+
+	return encl_page;
+
+out:
+	if (encl_page->va_offset)
+		sgx_free_va_slot(encl_page->va_page, encl_page->va_offset);
+	sgx_free_page(epc_page, encl);
+	if (va_page)
+		sgx_free_page(va_page, encl);
+	kfree(encl_page);
+	if (secs_epc_page)
+		sgx_free_page(secs_epc_page, encl);
+
+	if ((ret == -EBUSY)||(ret == -ERESTARTSYS))
+		return ERR_PTR(ret);
+
+	return ERR_PTR(-EFAULT);
+}
+
+static int isolate_range(struct sgx_encl *encl,
+			 struct sgx_range *rg, struct list_head *list)
+{
+	unsigned long address, end;
+	struct sgx_encl_page *encl_page;
+	struct vm_area_struct *vma;
+
+	address = rg->start_addr;
+	end = address + rg->nr_pages * PAGE_SIZE;
+
+	vma = sgx_find_vma(encl, address);
+	if (!vma)
+		return -EINVAL;
+
+	for (; address < end; address += PAGE_SIZE) {
+		encl_page = ERR_PTR(-EBUSY);
+		while (encl_page == ERR_PTR(-EBUSY))
+			/* bring back page in case it was evicted */
+			encl_page = sgx_fault_page(vma, address,
+						   SGX_FAULT_RESERVE, NULL);
+
+		if (IS_ERR(encl_page)) {
+			sgx_err(encl, "sgx: No page found at address 0x%lx\n",
+				 address);
+			return PTR_ERR(encl_page);
+		}
+
+		/* We do not need the reserved bit anymore as page
+		 * is removed from the load list
+		 */
+		mutex_lock(&encl->lock);
+		list_move_tail(&encl_page->load_list, list);
+		encl_page->flags &= ~SGX_ENCL_PAGE_RESERVED;
+		mutex_unlock(&encl->lock);
+	}
+
+	return 0;
+}
+
+static int __modify_range(struct sgx_encl *encl,
+			  struct sgx_range *rg, struct sgx_secinfo *secinfo)
+{
+	struct sgx_encl_page *encl_page, *tmp;
+	LIST_HEAD(list);
+	bool emodt = secinfo->flags & (SGX_SECINFO_TRIM | SGX_SECINFO_TCS);
+	unsigned int epoch = 0;
+	void *epc_va;
+	int ret = 0, cnt, status = 0;
+
+	ret = isolate_range(encl, rg, &list);
+	if (ret)
+		goto out;
+
+	if (list_empty(&list))
+		goto out;
+
+	/* EMODT / EMODPR */
+	list_for_each_entry_safe(encl_page, tmp, &list, load_list) {
+		if (!emodt && (encl_page->flags & SGX_ENCL_PAGE_TCS)) {
+			sgx_err(encl, "sgx: illegal request: page at\
+				address=0x%lx is a TCS, req flags=0x%llx\n",
+				encl_page->addr, secinfo->flags);
+			ret = -EINVAL;
+			continue;
+		}
+		mutex_lock(&encl->lock);
+		epc_va = sgx_get_page(encl_page->epc_page);
+		status = SGX_LOCKFAIL;
+		cnt = 0;
+		while (SGX_LOCKFAIL == status && cnt < SGX_EDMM_SPIN_COUNT) {
+			if (emodt) {
+				status = __emodt(secinfo, epc_va);
+				if (!status)
+					encl_page->flags |= SGX_ENCL_PAGE_TCS;
+			} else
+				status = __emodpr(secinfo, epc_va);
+			cnt++;
+		}
+
+		epoch = encl->shadow_epoch;
+		sgx_put_page(epc_va);
+		mutex_unlock(&encl->lock);
+
+		if (status) {
+			sgx_err(encl, "sgx: Page at address=0x%lx \
+				can't be modified err=%d req flags=0x%llx\n",
+				encl_page->addr, status, secinfo->flags);
+			ret = (ret) ? ret : status;
+		} else {
+			if (SGX_SECINFO_TRIM == secinfo->flags)
+				encl_page->flags |= SGX_ENCL_PAGE_TRIM;
+		}
+	}
+
+	/* ETRACK */
+	mutex_lock(&encl->lock);
+	sgx_etrack(encl, epoch);
+	mutex_unlock(&encl->lock);
+
+	smp_call_function(sgx_ipi_cb, NULL, 1);
+
+out:
+	if (!list_empty(&list)) {
+		mutex_lock(&encl->lock);
+		list_splice(&list, &encl->load_list);
+		mutex_unlock(&encl->lock);
+	}
+
+	return ret;
+}
+
+static long modify_range(struct sgx_range *rg, unsigned long flags)
+{
+	struct sgx_encl *encl;
+	struct sgx_secinfo secinfo;
+	struct sgx_range _rg;
+	unsigned long end = rg->start_addr + rg->nr_pages * PAGE_SIZE;
+	int ret = 0;
+
+	if (!sgx_has_sgx2)
+		return -ENOSYS;
+
+	if (rg->start_addr & (PAGE_SIZE - 1))
+		return -EINVAL;
+
+	if (!rg->nr_pages)
+		return -EINVAL;
+
+	ret = sgx_find_and_get_encl(rg->start_addr, &encl);
+	if (ret) {
+		pr_debug("sgx: No enclave found at start addr 0x%lx ret=%d\n",
+			 rg->start_addr, ret);
+		return ret;
+	}
+
+	if (end > encl->base + encl->size) {
+		ret = -EINVAL;
+		goto out;
+	}
+
+	memset(&secinfo, 0, sizeof(secinfo));
+	secinfo.flags = flags;
+
+	/*
+	 * Modifying the range by chunks of 16 pages:
+	 * these pages are removed from the load list. Bigger chunks
+	 * may empty EPC load lists and stall SGX.
+	 */
+	for (_rg.start_addr = rg->start_addr;
+	     _rg.start_addr < end;
+	     rg->nr_pages -= SGX_NR_MOD_CHUNK_PAGES,
+	     _rg.start_addr += SGX_NR_MOD_CHUNK_PAGES*PAGE_SIZE) {
+		_rg.nr_pages = rg->nr_pages > 0x10 ? 0x10 : rg->nr_pages;
+		ret = __modify_range(encl, &_rg, &secinfo);
+		if (ret)
+			break;
+	}
+
+out:
+	kref_put(&encl->refcount, sgx_encl_release);
+	return ret;
+}
+
+long sgx_ioc_page_modpr(struct file *filep, unsigned int cmd,
+			unsigned long arg)
+{
+	struct sgx_modification_param *p =
+		(struct sgx_modification_param *) arg;
+
+	/*
+	 * Only RWX flags in mask are allowed
+	 * Restricting WR w/o RD is not allowed
+	 */
+	if (p->flags & ~(SGX_SECINFO_R | SGX_SECINFO_W | SGX_SECINFO_X))
+		return -EINVAL;
+	if (!(p->flags & SGX_SECINFO_R) &&
+	    (p->flags & SGX_SECINFO_W))
+		return -EINVAL;
+	return modify_range(&p->range, p->flags);
+}
+
+/**
+ * sgx_ioc_page_to_tcs() - Pages defined in range are switched to TCS.
+ * These pages should be of type REG.
+ * eaccept need to be invoked after that.
+ * @arg range address of pages to be switched
+ */
+long sgx_ioc_page_to_tcs(struct file *filep, unsigned int cmd,
+			 unsigned long arg)
+{
+	return modify_range((struct sgx_range *)arg, SGX_SECINFO_TCS);
+}
+
+/**
+ * sgx_ioc_trim_page() - Pages defined in range are being trimmed.
+ * These pages still belong to the enclave and can not be removed until
+ * eaccept has been invoked
+ * @arg range address of pages to be trimmed
+ */
+long sgx_ioc_trim_page(struct file *filep, unsigned int cmd,
+		       unsigned long arg)
+{
+	return modify_range((struct sgx_range *)arg, SGX_SECINFO_TRIM);
+}
+
+static int remove_page(struct sgx_encl *encl, unsigned long address,
+		       bool trim)
+{
+	struct sgx_encl_page *encl_page;
+	struct vm_area_struct *vma;
+	struct sgx_va_page *va_page;
+
+	vma = sgx_find_vma(encl, address);
+	if (!vma)
+		return -EINVAL;
+
+	encl_page = sgx_fault_page(vma, address, SGX_FAULT_RESERVE, NULL);
+	if (IS_ERR(encl_page))
+		return (PTR_ERR(encl_page) == -EBUSY) ? -EBUSY : -EINVAL;
+
+	if (trim && !(encl_page->flags & SGX_ENCL_PAGE_TRIM)) {
+		encl_page->flags &= ~SGX_ENCL_PAGE_RESERVED;
+		return -EINVAL;
+	}
+
+	if (!(encl_page->flags & SGX_ENCL_PAGE_ADDED)) {
+		encl_page->flags &= ~SGX_ENCL_PAGE_RESERVED;
+		return -EINVAL;
+	}
+
+	mutex_lock(&encl->lock);
+
+	radix_tree_delete(&encl->page_tree, encl_page->addr >> PAGE_SHIFT);
+	va_page = encl_page->va_page;
+
+	if (va_page) {
+		sgx_free_va_slot(va_page, encl_page->va_offset);
+
+		if (sgx_va_slots_empty(va_page)) {
+			list_del(&va_page->list);
+			sgx_free_page(va_page->epc_page, encl);
+			kfree(va_page);
+		}
+	}
+
+	if (encl_page->epc_page) {
+		list_del(&encl_page->load_list);
+		zap_vma_ptes(vma, encl_page->addr, PAGE_SIZE);
+		sgx_free_page(encl_page->epc_page, encl);
+		encl->secs_child_cnt--;
+	}
+
+	mutex_unlock(&encl->lock);
+
+	kfree(encl_page);
+
+	return 0;
+}
+
+/**
+ * sgx_ioc_page_notify_accept() - Pages defined in range will be moved to
+ * the trimmed list, i.e. they can be freely removed from now. These pages
+ * should have PT_TRIM page type and should have been eaccepted priorly
+ * @arg range address of pages
+ */
+long sgx_ioc_page_notify_accept(struct file *filep, unsigned int cmd,
+				unsigned long arg)
+{
+	struct sgx_range *rg;
+	unsigned long address, end;
+	struct sgx_encl *encl;
+	int ret, tmp_ret = 0;
+
+	if (!sgx_has_sgx2)
+		return -ENOSYS;
+
+	rg = (struct sgx_range *)arg;
+
+	address = rg->start_addr;
+	address &= ~(PAGE_SIZE-1);
+	end = address + rg->nr_pages * PAGE_SIZE;
+
+	ret = sgx_find_and_get_encl(address, &encl);
+	if (ret) {
+		pr_debug("sgx: No enclave found at start address 0x%lx\n",
+			address);
+		return ret;
+	}
+
+	for (; address < end; address += PAGE_SIZE) {
+		tmp_ret = remove_page(encl, address, true);
+		if (tmp_ret) {
+			sgx_dbg(encl, "sgx: remove failed, addr=0x%lx ret=%d\n",
+				 address, tmp_ret);
+			ret = tmp_ret;
+			continue;
+		}
+	}
+
+	kref_put(&encl->refcount, sgx_encl_release);
+
+	return ret;
+}
+
+
+
+/**
+ * sgx_ioc_page_remove() - Pages defined by address will be removed
+ * @arg address of page
+ */
+long sgx_ioc_page_remove(struct file *filep, unsigned int cmd,
+			 unsigned long arg)
+{
+	struct sgx_encl *encl;
+	unsigned long address = *((unsigned long *) arg);
+	int ret;
+
+	if (!sgx_has_sgx2)
+		return -ENOSYS;
+
+	if (sgx_find_and_get_encl(address, &encl)) {
+		pr_debug("sgx: No enclave found at start address 0x%lx\n",
+			 address);
+		return -EINVAL;
+	}
+
+	ret = remove_page(encl, address, false);
+	if (ret) {
+		pr_debug("sgx: Failed to remove page, address=0x%lx ret=%d\n",
+			  address, ret);
+	}
+
+	kref_put(&encl->refcount, sgx_encl_release);
+	return ret;
+}
+
 typedef long (*sgx_ioc_t)(struct file *filep, unsigned int cmd,
 			  unsigned long arg);
 
@@ -949,6 +1455,21 @@ long sgx_ioctl(struct file *filep, unsigned int cmd, unsigned long arg)
 	case SGX_IOC_ENCLAVE_INIT:
 		handler = sgx_ioc_enclave_init;
 		break;
+	case SGX_IOC_ENCLAVE_EMODPR:
+		handler = sgx_ioc_page_modpr;
+		break;
+	case SGX_IOC_ENCLAVE_MKTCS:
+		handler = sgx_ioc_page_to_tcs;
+		break;
+	case SGX_IOC_ENCLAVE_TRIM:
+		handler = sgx_ioc_trim_page;
+		break;
+	case SGX_IOC_ENCLAVE_NOTIFY_ACCEPT:
+		handler = sgx_ioc_page_notify_accept;
+		break;
+	case SGX_IOC_ENCLAVE_PAGE_REMOVE:
+		handler = sgx_ioc_page_remove;
+		break;
 	default:
 		return -ENOIOCTLCMD;
 	}
diff --git a/sgx_main.c b/sgx_main.c
index 91fee13..7e22bcc 100644
--- a/sgx_main.c
+++ b/sgx_main.c
@@ -70,7 +70,7 @@
 #include <linux/platform_device.h>
 
 #define DRV_DESCRIPTION "Intel SGX Driver"
-#define DRV_VERSION "0.10"
+#define DRV_VERSION "0.11"
 
 #define ENCL_SIZE_MAX_64 (64ULL * 1024ULL * 1024ULL * 1024ULL)
 #define ENCL_SIZE_MAX_32 (2ULL * 1024ULL * 1024ULL * 1024ULL)
diff --git a/sgx_page_cache.c b/sgx_page_cache.c
index 0cb9b4e..728ad90 100644
--- a/sgx_page_cache.c
+++ b/sgx_page_cache.c
@@ -242,19 +242,32 @@ static void sgx_eblock(struct sgx_encl *encl,
 
 }
 
-static void sgx_etrack(struct sgx_encl *encl)
+bool sgx_etrack(struct sgx_encl *encl, unsigned int epoch)
 {
 	void *epc;
 	int ret;
+	bool ipi = false;
+
+	/* If someone already called etrack in the meantime */
+	if (epoch < encl->shadow_epoch)
+		return false;
 
 	epc = sgx_get_page(encl->secs_page.epc_page);
 	ret = __etrack(epc);
 	sgx_put_page(epc);
-
-	if (ret) {
+	encl->shadow_epoch++;
+
+	if (ret == SGX_PREV_TRK_INCMPL) {
+		sgx_dbg(encl, "ETRACK returned %d\n", ret);
+		smp_call_function(sgx_ipi_cb, NULL, 1);
+		BUG_ON(__etrack(epc));
+		ipi = true;
+	} else if (ret) {
 		sgx_crit(encl, "ETRACK returned %d\n", ret);
 		sgx_invalidate(encl, true);
 	}
+
+	return ipi;
 }
 
 static int __sgx_ewb(struct sgx_encl *encl,
@@ -362,7 +375,7 @@ static void sgx_write_pages(struct sgx_encl *encl, struct list_head *src)
 	}
 
 	/* ETRACK */
-	sgx_etrack(encl);
+	sgx_etrack(encl, encl->shadow_epoch);
 
 	/* EWB */
 	while (!list_empty(src)) {
diff --git a/sgx_user.h b/sgx_user.h
index 503f6be..d268b45 100644
--- a/sgx_user.h
+++ b/sgx_user.h
@@ -71,6 +71,16 @@
 	_IOW(SGX_MAGIC, 0x01, struct sgx_enclave_add_page)
 #define SGX_IOC_ENCLAVE_INIT \
 	_IOW(SGX_MAGIC, 0x02, struct sgx_enclave_init)
+#define SGX_IOC_ENCLAVE_EMODPR \
+	_IOW(SGX_MAGIC, 0x09, struct sgx_modification_param)
+#define SGX_IOC_ENCLAVE_MKTCS \
+	_IOW(SGX_MAGIC, 0x0a, struct sgx_range)
+#define SGX_IOC_ENCLAVE_TRIM \
+	_IOW(SGX_MAGIC, 0x0b, struct sgx_range)
+#define SGX_IOC_ENCLAVE_NOTIFY_ACCEPT \
+	_IOW(SGX_MAGIC, 0x0c, struct sgx_range)
+#define SGX_IOC_ENCLAVE_PAGE_REMOVE \
+	_IOW(SGX_MAGIC, 0x0d, unsigned long)
 
 /* SGX leaf instruction return values */
 #define SGX_SUCCESS			0
@@ -92,6 +102,7 @@
 #define SGX_INVALID_LICENSE		16
 #define SGX_PREV_TRK_INCMPL		17
 #define SGX_PG_IS_SECS			18
+#define SGX_PAGE_NOT_MODIFIABLE		20
 #define SGX_INVALID_CPUSVN		32
 #define SGX_INVALID_ISVSVN		64
 #define SGX_UNMASKED_EVENT		128
@@ -142,4 +153,22 @@ struct sgx_enclave_destroy {
 	__u64	addr;
 } __packed;
 
+
+/*
+ *     SGX2.0 definitions
+ */
+
+#define SGX_GROW_UP_FLAG	1
+#define SGX_GROW_DOWN_FLAG	2
+
+struct sgx_range {
+	unsigned long start_addr;
+	unsigned int nr_pages;
+};
+
+struct sgx_modification_param {
+	struct sgx_range range;
+	unsigned long flags;
+};
+
 #endif /* _UAPI_ASM_X86_SGX_H */
diff --git a/sgx_util.c b/sgx_util.c
index 614a635..16276f9 100644
--- a/sgx_util.c
+++ b/sgx_util.c
@@ -145,7 +145,7 @@ void sgx_invalidate(struct sgx_encl *encl, bool flush_cpus)
 		sgx_flush_cpus(encl);
 }
 
-static void sgx_ipi_cb(void *info)
+void sgx_ipi_cb(void *info)
 {
 }
 
@@ -186,10 +186,10 @@ int sgx_find_encl(struct mm_struct *mm, unsigned long addr,
 	return 0;
 }
 
-static int sgx_eldu(struct sgx_encl *encl,
-		    struct sgx_encl_page *encl_page,
-		    struct sgx_epc_page *epc_page,
-		    bool is_secs)
+int sgx_eldu(struct sgx_encl *encl,
+	     struct sgx_encl_page *encl_page,
+	     struct sgx_epc_page *epc_page,
+	     bool is_secs)
 {
 	struct page *backing;
 	struct page *pcmd;
@@ -253,7 +253,8 @@ out:
 }
 
 static struct sgx_encl_page *sgx_do_fault(struct vm_area_struct *vma,
-					  unsigned long addr, unsigned int flags)
+					  unsigned long addr, unsigned int flags,
+				          struct vm_fault *vmf)
 {
 	struct sgx_encl *encl = vma->vm_private_data;
 	struct sgx_encl_page *entry;
@@ -261,6 +262,8 @@ static struct sgx_encl_page *sgx_do_fault(struct vm_area_struct *vma,
 	struct sgx_epc_page *secs_epc_page = NULL;
 	bool reserve = (flags & SGX_FAULT_RESERVE) != 0;
 	int rc = 0;
+	bool write = (vmf) ? (FAULT_FLAG_WRITE & vmf->flags) : false;
+
 
 	/* If process was forked, VMA is still there but vm_private_data is set
 	 * to NULL.
@@ -271,6 +274,14 @@ static struct sgx_encl_page *sgx_do_fault(struct vm_area_struct *vma,
 	mutex_lock(&encl->lock);
 
 	entry = radix_tree_lookup(&encl->page_tree, addr >> PAGE_SHIFT);
+	if (vmf && !entry) {
+		entry = sgx_augment_encl(vma, addr, write);
+		goto out;
+	}
+
+	/* No entry found can not happen in 'reloading an evicted page'
+	 * flow.
+	 */
 	if (!entry) {
 		rc = -EFAULT;
 		goto out;
@@ -371,12 +382,13 @@ out:
 
 struct sgx_encl_page *sgx_fault_page(struct vm_area_struct *vma,
 				     unsigned long addr,
-				     unsigned int flags)
+				     unsigned int flags,
+				     struct vm_fault *vmf)
 {
 	struct sgx_encl_page *entry;
 
 	do {
-		entry = sgx_do_fault(vma, addr, flags);
+		entry = sgx_do_fault(vma, addr, flags, vmf);
 		if (!(flags & SGX_FAULT_RESERVE))
 			break;
 	} while (PTR_ERR(entry) == -EBUSY);
diff --git a/sgx_vma.c b/sgx_vma.c
index 4dbe26c..d76b948 100644
--- a/sgx_vma.c
+++ b/sgx_vma.c
@@ -75,6 +75,12 @@ static void sgx_vma_open(struct vm_area_struct *vma)
 	if (!encl)
 		return;
 
+	/* protect from fork */
+	if (encl->mm != current->mm) {
+		vma->vm_private_data = NULL;
+		return;
+	}
+
 	/* kref cannot underflow because ECREATE ioctl checks that there is only
 	 * one single VMA for the enclave before proceeding.
 	 */
@@ -89,7 +95,6 @@ static void sgx_vma_close(struct vm_area_struct *vma)
 
 	mutex_lock(&encl->lock);
 	zap_vma_ptes(vma, vma->vm_start, vma->vm_end - vma->vm_start);
-	encl->flags |= SGX_ENCL_DEAD;
 	mutex_unlock(&encl->lock);
 	kref_put(&encl->refcount, sgx_encl_release);
 }
@@ -111,7 +116,7 @@ static int sgx_vma_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
 #endif
 	struct sgx_encl_page *entry;
 
-	entry = sgx_fault_page(vma, addr, 0);
+	entry = sgx_fault_page(vma, addr, 0, vmf);
 
 	if (!IS_ERR(entry) || PTR_ERR(entry) == -EBUSY)
 		return VM_FAULT_NOPAGE;
@@ -210,7 +215,7 @@ static int sgx_vma_access(struct vm_area_struct *vma, unsigned long addr,
 				entry->flags &= ~SGX_ENCL_PAGE_RESERVED;
 
 			entry = sgx_fault_page(vma, (addr + i) & PAGE_MASK,
-					       SGX_FAULT_RESERVE);
+					       SGX_FAULT_RESERVE, NULL);
 			if (IS_ERR(entry)) {
 				ret = PTR_ERR(entry);
 				entry = NULL;
-- 
2.7.4

